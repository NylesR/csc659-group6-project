{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "060606d4-538a-43ef-8bd9-50bd1a3d87bd",
      "metadata": {
        "id": "060606d4-538a-43ef-8bd9-50bd1a3d87bd"
      },
      "outputs": [],
      "source": [
        "# Import required libraries for data manipulation, visualization, and machine learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt\n",
        "from collections import Counter\n",
        "\n",
        "# Import scikit-learn modules for Random Forest classification and evaluation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score)\n",
        "from sklearn.metrics import (f1_score, precision_score, recall_score,\n",
        "                             accuracy_score, classification_report,\n",
        "                             roc_curve, roc_auc_score, confusion_matrix,\n",
        "                             ConfusionMatrixDisplay, RocCurveDisplay)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de94d508",
      "metadata": {},
      "source": [
        "### 1. LIBRARY VERSION TRACKING\n",
        "- Create a comprehensive table of all library versions used in the project\n",
        "- This ensures reproducibility by documenting exact package versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631ab73f",
      "metadata": {},
      "outputs": [],
      "source": [
        "versions_data = {\n",
        "    'Library': [\n",
        "        'Python',\n",
        "        'pandas',\n",
        "        'numpy', \n",
        "        'matplotlib',\n",
        "        'scikit-learn',\n",
        "        'math',\n",
        "        'collections'\n",
        "    ],\n",
        "    'Version': [\n",
        "        sys.version.split()[0],\n",
        "        pd.__version__,\n",
        "        np.__version__,\n",
        "        matplotlib.__version__,\n",
        "        sklearn.__version__,\n",
        "        'Python built-in',\n",
        "        'Python built-in'\n",
        "    ],\n",
        "    'Purpose': [\n",
        "        'Programming language',\n",
        "        'Data manipulation and analysis',\n",
        "        'Numerical computations',\n",
        "        'Data visualization',\n",
        "        'Machine learning algorithms',\n",
        "        'Mathematical functions (sqrt)',\n",
        "        'Container datatypes (Counter - imported but not used)'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame for better display\n",
        "versions_df = pd.DataFrame(versions_data)\n",
        "\n",
        "# Create markdown table format for easy inclusion in reports/documentation\n",
        "print(\"MARKDOWN TABLE FORMAT:\\n\")\n",
        "print(\"| Library | Version | Purpose |\")\n",
        "print(\"|---------|---------|---------|\")\n",
        "for _, row in versions_df.iterrows():\n",
        "    print(f\"| {row['Library']} | {row['Version']} | {row['Purpose']} |\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38d68b1",
      "metadata": {},
      "source": [
        "### 1.1 INITIAL CONFIGURATION (Before Training)\n",
        "- Define all experimental settings that will be used in the Random Forest model\n",
        "- This configuration captures the experimental design for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48314950",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Data provenance settings object\n",
        "rf_settings = {\n",
        "    # Data configuration - file path and target variable settings\n",
        "    'data_path': \"./data/studentdras.csv\",\n",
        "    'target_column': 'Target',\n",
        "    'test_size': 0.2,  # 20% of data for testing\n",
        "    'shuffle': True,    # Randomly shuffle data before splitting\n",
        "    'random_state': 42, # For reproducible results\n",
        "    \n",
        "    # Model hyperparameters for Random Forest tuning\n",
        "    'n_trees_options': [400, 600, 800],  # Number of trees to try\n",
        "    'max_depth_multipliers': [0.5, 1.0, 2.0],  # Multipliers for sqrt(n_features) to set max_depth\n",
        "    'oob_score': True,  # Calculate out-of-bag score for model validation\n",
        "    \n",
        "    # Cross-validation settings\n",
        "    'cv_folds': 3,  # Number of folds for cross-validation\n",
        "    \n",
        "    # Evaluation metrics configuration\n",
        "    'f1_average': 'macro',  # Use macro averaging for multi-class F1 score\n",
        "    'confusion_matrix_labels': [\"Dropout(0)\", \"Enrolled(1)\", \"Graduate(2)\"],  # Class labels for visualization\n",
        "    \n",
        "    # Visualization settings for plots\n",
        "    'confusion_matrix_figsize': (5, 5),\n",
        "    'feature_importance_figsize': (12, 9),\n",
        "    'confusion_matrix_cmap': 'Blues',  # Color map for confusion matrix\n",
        "    'grid_visible': False  # Whether to show grid in plots\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a73d862",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset using the configured path\n",
        "students = rf_settings['data_path']\n",
        "students_df = pd.read_csv(students)\n",
        "\n",
        "# Display first few rows to inspect the data structure\n",
        "students_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95f62b51-8968-4e33-9033-fd5f9c0f097f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95f62b51-8968-4e33-9033-fd5f9c0f097f",
        "outputId": "d7c3748c-6e25-48ff-d041-8e7240deed5a"
      },
      "outputs": [],
      "source": [
        "# Prepare features (X) by removing the target column\n",
        "X_data = students_df.drop(rf_settings['target_column'], axis=1)\n",
        "\n",
        "# Extract target variable (y) for classification\n",
        "y_data = students_df[rf_settings['target_column']]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# This ensures we have separate data for training and evaluating the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=rf_settings['test_size'], shuffle=rf_settings['shuffle'])\n",
        "\n",
        "# Print dataset shapes to verify the split\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9935f3c2-10ed-4b35-962f-1aa6f22696c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9935f3c2-10ed-4b35-962f-1aa6f22696c3",
        "outputId": "330395f6-2eb5-4440-bd08-dccec1e65eae"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning: Test different combinations of number of trees and max depth\n",
        "n_trees = rf_settings['n_trees_options']\n",
        "sqrt_n_features = sqrt(X_train.shape[1])  # Calculate sqrt of number of features\n",
        "max_depths = [(int)(multiplier*sqrt_n_features) for multiplier in rf_settings['max_depth_multipliers']]  # Generate max_depth values\n",
        "\n",
        "# Initialize variables to track the best model\n",
        "best_model = None\n",
        "best_oob = 0\n",
        "\n",
        "# Grid search through all combinations of hyperparameters\n",
        "for trees in n_trees:\n",
        "    print(\"============================================\")\n",
        "    for depth in max_depths:\n",
        "        # Create and train Random Forest with current hyperparameters\n",
        "        clf = RandomForestClassifier(n_estimators=trees, max_depth=depth, random_state=rf_settings['random_state'], oob_score=rf_settings['oob_score'])\n",
        "        clf.fit(X_train, y_train)\n",
        "        \n",
        "        # Get out-of-bag score (unbiased estimate of generalization error)\n",
        "        oob_score = clf.oob_score_\n",
        "        \n",
        "        # Update best model if current model has better OOB score\n",
        "        if best_oob < oob_score:\n",
        "            best_model = clf\n",
        "            best_oob = oob_score\n",
        "        \n",
        "        print(f\"Trees: {trees}, Max Depth: {depth}, OOB Score: {oob_score:.3f}\")\n",
        "\n",
        "print(\"============================================\")\n",
        "print(f\"Best OOB Score: {best_oob:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pqb0lF5UT0YL",
      "metadata": {
        "id": "pqb0lF5UT0YL"
      },
      "outputs": [],
      "source": [
        "# Perform cross-validation on the best model using the full dataset\n",
        "# This gives us a more robust estimate of model performance\n",
        "cv_scores = cross_val_score(best_model, X_data, y_data, cv=rf_settings['cv_folds'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344fe6f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "344fe6f6",
        "outputId": "dc19f2ed-64d6-40f3-842b-9851d98f6484"
      },
      "outputs": [],
      "source": [
        "# Display cross-validation results\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(f\"Mean CV score: {cv_scores.mean():.3f}\")\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate and display key performance metrics\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average=rf_settings['f1_average'])}\")\n",
        "print(f\"Accuracy:{accuracy_score(y_test, y_pred):.3f}\")\n",
        "\n",
        "# Create and display confusion matrix to understand classification performance\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm,\n",
        "    display_labels=rf_settings['confusion_matrix_labels']\n",
        ")\n",
        "\n",
        "# Plot confusion matrix with custom styling\n",
        "fig,ax = plt.subplots(figsize=rf_settings['confusion_matrix_figsize'])\n",
        "cm_display.plot(\n",
        "    cmap=plt.cm.get_cmap(rf_settings['confusion_matrix_cmap']),\n",
        "    ax=ax,\n",
        "    values_format='d'\n",
        ")\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "ax.set_xlabel(\"Predicted Label\")\n",
        "ax.set_ylabel(\"True Label\")\n",
        "plt.grid(rf_settings['grid_visible'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48fb9671",
      "metadata": {
        "id": "48fb9671"
      },
      "outputs": [],
      "source": [
        "# Feature importance analysis using Gini importance (built into Random Forest)\n",
        "gini_importances = best_model.feature_importances_\n",
        "\n",
        "# Create DataFrame for Gini importance and sort by importance\n",
        "gini_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Gini Importance': gini_importances\n",
        "})\n",
        "gini_df = gini_df.sort_values(by='Gini Importance', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OWORgsgruNBb",
      "metadata": {
        "id": "OWORgsgruNBb"
      },
      "outputs": [],
      "source": [
        "# Feature importance analysis using Mean Decrease in Accuracy (MDA)\n",
        "# This method shuffles each feature and measures the drop in accuracy\n",
        "mda_importances = []\n",
        "initial_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# For each feature, shuffle its values and measure accuracy drop\n",
        "for i in range(X_data.shape[1]):\n",
        "    X_test_copy = X_test.copy()\n",
        "    # Shuffle the values in the specified feature column\n",
        "    shuffled_column_values = X_test_copy.iloc[:, i].values.copy()\n",
        "    np.random.shuffle(shuffled_column_values)\n",
        "    X_test_copy.iloc[:, i] = shuffled_column_values\n",
        "\n",
        "    # Calculate accuracy with shuffled feature\n",
        "    shuff_accuracy = accuracy_score(y_test, best_model.predict(X_test_copy))\n",
        "    # Importance is the drop in accuracy when feature is shuffled\n",
        "    mda_importances.append(initial_accuracy - shuff_accuracy)\n",
        "\n",
        "# Create DataFrame for MDA importance and sort by importance\n",
        "mda_df = pd.DataFrame({'Feature': X_data.columns, 'Decrease in Accuracy': mda_importances}).sort_values('Decrease in Accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h7HRkUwfYk0I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "h7HRkUwfYk0I",
        "outputId": "c53d4e84-8fe8-402e-b66c-0fad843c872e"
      },
      "outputs": [],
      "source": [
        "# Create side-by-side comparison of both feature importance methods\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=rf_settings['feature_importance_figsize'])\n",
        "\n",
        "# Plot MDA feature importance\n",
        "ax1.barh(mda_df['Feature'], mda_df['Decrease in Accuracy'])\n",
        "ax1.set_title('Feature Importance (MDA)')\n",
        "ax1.set_xlabel('Mean Decrease Accuracy')\n",
        "\n",
        "# Plot Gini feature importance\n",
        "ax2.barh(gini_df['Feature'], gini_df['Gini Importance'])\n",
        "ax2.set_title('Feature Importance (Gini)')\n",
        "ax2.set_xlabel('Mean Decrease Gini')\n",
        "\n",
        "# Adjust layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uKFZR__FfDEx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKFZR__FfDEx",
        "outputId": "97607b05-7b44-45a6-82ab-116932bf8485"
      },
      "outputs": [],
      "source": [
        "print(\"Lets go Team 6!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
